{
    "Company name": "Schwarz Corporate Solutions",
    "Full or Part time?": "Full Time",
    "Date published": " 2 weeks ago",
    "Content of job description": "As a central IT service provider, Schwarz IT KG is responsible for the selection, provision, operation and further development of IT infrastructures, IT platforms and business applications. Schwarz IT thus provides IT services for Kaufland and Lidl as well as for Schwarz Dienstleistung KG and Schwarz Zentrale Dienste KG. In order to optimally support the departments in their business processes with IT solutions, Schwarz IT takes up the requirements of the departments in consultation meetings and develops professional and efficient IT solutions together with them. You have the opportunity to take a leading role in the development of a generic software framework for computer vision applications. You will accompany, develop and expand AI applications within Schwarz IT from prototype and pilot to operationalised product with a focus on computer vision and have the opportunity to take responsibility for innovative and dynamic AIoT products. You will be responsible for driving the development of AI products within Schwarz IT with a focus on AIoT.\nI am Max and I am responsible for the Computer Vision & AIoT domain at Schwarz IT. I am looking for you to join my team! As a central IT service provider, Schwarz IT is responsible for the selection, provision, operation and further development of IT solutions for all divisions of the Schwarz Group, such as LIDL, Kaufland, PreZero and Schwarz Produktion. I look forward to receiving your application via our job portal. Please contact me personally if you have any questions or are interested in the position.\nYou design and implement a scalable product for anomaly detection on large IoT time series data, e.g. for monitoring logs or IoT data from machines\nYou design a new architecture to fix performance issues and make the system scalable for high data volumes\nYou use modern data streaming technologies such as Kafka and optimise the processing of large data streams in real time\nYou implement robust and scalable software components using PySpark, Spark Streaming and modern data engineering technologies such as Iceberg\nYou are responsible for the extension of anomaly types and signals, with a focus on time-series forecasting and data science algorithms for IOT data\nYou combine efficient data streaming tools with innovative data engineering technologies to build a future-proof AIoT architecture on STACKIT\nYou have profound and practical experience with data streaming technologies such as Kafka and know the challenges of scaling real-time data streams\nYou have initial experience in processing large IoT time series data with PySpark and have experience in designing data architectures for time series handling\nYou are proficient in programming languages such as Python or C++ (possibly also Rust) and have experience in implementing scalable software solutions\nYou have in-depth knowledge of Kubernetes and Docker as well as experience with Azure DevOps\nYou can familiarise yourself with complex technical challenges and offer pragmatic, scalable solutions"
}